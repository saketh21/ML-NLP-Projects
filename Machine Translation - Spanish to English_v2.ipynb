{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A startup has hired you to build a machine translation model for its new multilingual messaging app. Right now the challenge is to build an __Spanish to English__ machine translation model for the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import unidecode\n",
    "from keras.preprocessing.sequence import pad_sequences # for padding\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint # to prevent overfitting and save the best model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Spanish to English Sentences\n",
    "\n",
    "The dataset can be downloaded from here : http://www.manythings.org/anki/spa-eng.zip\n",
    "\n",
    "You can find several other similar datasets for different languages at http://www.manythings.org/anki/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "txt = read_text(\"spa.txt\")\n",
    "\n",
    "# convert text into list of \n",
    "sp_eng = to_lines(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123012"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check count of sentence pairs in the data\n",
    "len(sp_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into array\n",
    "sp_eng = np.array(sp_eng)\n",
    "\n",
    "# empty lists\n",
    "eng_l = []\n",
    "sp_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in sp_eng[:,0]:\n",
    "      eng_l.append(i)\n",
    "\n",
    "for i in sp_eng[:,1]:\n",
    "      sp_l.append(i)\n",
    "        \n",
    "data = pd.DataFrame({'spa':sp_l, 'eng':eng_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spa</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123007</th>\n",
       "      <td>Hay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente diner...</td>\n",
       "      <td>There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123008</th>\n",
       "      <td>Una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque está...</td>\n",
       "      <td>A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123009</th>\n",
       "      <td>Como suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a ...</td>\n",
       "      <td>Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123010</th>\n",
       "      <td>Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra ...</td>\n",
       "      <td>If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123011</th>\n",
       "      <td>Puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboración. Sin embargo, si animamos a los miembros a contribuir frase...</td>\n",
       "      <td>It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                            spa  \\\n",
       "123007  Hay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente diner...   \n",
       "123008  Una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque está...   \n",
       "123009  Como suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a ...   \n",
       "123010  Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra ...   \n",
       "123011  Puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboración. Sin embargo, si animamos a los miembros a contribuir frase...   \n",
       "\n",
       "                                                                                                                                                                                                            eng  \n",
       "123007  There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college educ...  \n",
       "123008  A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climat...  \n",
       "123009  Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Goo...  \n",
       "123010  If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until t...  \n",
       "123011  It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages r...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates from the Spanish sentences\n",
    "data.drop_duplicates(subset=['spa'],inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Let's Preprocess the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess the text\n",
    "def cleaner(text):\n",
    "    newString = text.lower()\n",
    "    unaccented_string = unidecode.unidecode(newString)\n",
    "    newString = re.sub(\"'\",'', unaccented_string) \n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    tokens = newString.split()\n",
    "    return (\" \".join(tokens)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess english text\n",
    "cleaned_eng = []\n",
    "for t in data['eng']:\n",
    "    cleaned_eng.append(cleaner(t)) \n",
    "    \n",
    "# preprocess Spanish text\n",
    "cleaned_spa = []\n",
    "for t in data['spa']:\n",
    "    cleaned_spa.append(cleaner(t)) \n",
    "\n",
    "    \n",
    "data['cleaned_eng']=cleaned_eng\n",
    "data['cleaned_spa']=cleaned_spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spa</th>\n",
       "      <th>eng</th>\n",
       "      <th>cleaned_eng</th>\n",
       "      <th>cleaned_spa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123007</th>\n",
       "      <td>Hay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente diner...</td>\n",
       "      <td>There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college educ...</td>\n",
       "      <td>there are mothers and fathers who will lie awake after the children fall asleep and wonder how theyll make the mortgage or pay their doctors bills or save enough for their childs college education</td>\n",
       "      <td>hay madres y padres que se quedan despiertos despues de que sus hijos se hayan dormido y se preguntan como conseguir pagar la hipoteca o las facturas del medico o como ahorrar el suficiente dinero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123008</th>\n",
       "      <td>Una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque está...</td>\n",
       "      <td>A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climat...</td>\n",
       "      <td>a carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities some people try to reduce their carbon footprint because they are concerned about climate...</td>\n",
       "      <td>una huella de carbono es la cantidad de contaminacion de dioxido de carbono que producimos como producto de nuestras actividades algunas personas intentan reducir su huella de carbono porque estan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123009</th>\n",
       "      <td>Como suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a ...</td>\n",
       "      <td>Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Goo...</td>\n",
       "      <td>since there are usually multiple websites on any given topic i usually just click the back button when i arrive on any webpage that has pop up advertising i just go to the next page found by googl...</td>\n",
       "      <td>como suele haber varias paginas web sobre cualquier tema normalmente solo le doy al boton de retroceso cuando entro en una pagina web que tiene anuncios en ventanas emergentes simplemente voy a la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123010</th>\n",
       "      <td>Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra ...</td>\n",
       "      <td>If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until t...</td>\n",
       "      <td>if you want to sound like a native speaker you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until th...</td>\n",
       "      <td>si quieres sonar como un hablante nativo debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123011</th>\n",
       "      <td>Puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboración. Sin embargo, si animamos a los miembros a contribuir frase...</td>\n",
       "      <td>It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages r...</td>\n",
       "      <td>it may be impossible to get a completely error free corpus due to the nature of this kind of collaborative effort however if we encourage members to contribute sentences in their own languages rat...</td>\n",
       "      <td>puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboracion sin embargo si animamos a los miembros a contribuir frases ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                            spa  \\\n",
       "123007  Hay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente diner...   \n",
       "123008  Una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque está...   \n",
       "123009  Como suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a ...   \n",
       "123010  Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra ...   \n",
       "123011  Puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboración. Sin embargo, si animamos a los miembros a contribuir frase...   \n",
       "\n",
       "                                                                                                                                                                                                            eng  \\\n",
       "123007  There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college educ...   \n",
       "123008  A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climat...   \n",
       "123009  Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Goo...   \n",
       "123010  If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until t...   \n",
       "123011  It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages r...   \n",
       "\n",
       "                                                                                                                                                                                                    cleaned_eng  \\\n",
       "123007     there are mothers and fathers who will lie awake after the children fall asleep and wonder how theyll make the mortgage or pay their doctors bills or save enough for their childs college education   \n",
       "123008  a carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities some people try to reduce their carbon footprint because they are concerned about climate...   \n",
       "123009  since there are usually multiple websites on any given topic i usually just click the back button when i arrive on any webpage that has pop up advertising i just go to the next page found by googl...   \n",
       "123010  if you want to sound like a native speaker you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until th...   \n",
       "123011  it may be impossible to get a completely error free corpus due to the nature of this kind of collaborative effort however if we encourage members to contribute sentences in their own languages rat...   \n",
       "\n",
       "                                                                                                                                                                                                    cleaned_spa  \n",
       "123007  hay madres y padres que se quedan despiertos despues de que sus hijos se hayan dormido y se preguntan como conseguir pagar la hipoteca o las facturas del medico o como ahorrar el suficiente dinero...  \n",
       "123008  una huella de carbono es la cantidad de contaminacion de dioxido de carbono que producimos como producto de nuestras actividades algunas personas intentan reducir su huella de carbono porque estan...  \n",
       "123009  como suele haber varias paginas web sobre cualquier tema normalmente solo le doy al boton de retroceso cuando entro en una pagina web que tiene anuncios en ventanas emergentes simplemente voy a la...  \n",
       "123010  si quieres sonar como un hablante nativo debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra v...  \n",
       "123011  puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboracion sin embargo si animamos a los miembros a contribuir frases ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(data['cleaned_spa'],data['cleaned_eng'], test_size = 0.2, random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving validation data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing validation data into new variables for later use\n",
    "x_val_original = x_val\n",
    "y_val_original = y_val\n",
    "\n",
    "# reset index\n",
    "y_val_original.reset_index(inplace=True, drop=True)\n",
    "x_val_original.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Text Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of word-frequency pairs for the spanish text data in the training set (*x_tr*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "# create word-frequency pair dictionary\n",
    "source_word_freq = build_vocab(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find proportion of tokens occurring less than a threshold value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 42.45175936435868\n",
      "Total Coverage of rare words: 1.6922193411412563\n"
     ]
    }
   ],
   "source": [
    "# set threshold value for rare words\n",
    "thresh=2\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in source_word_freq.items():\n",
    "  tot_cnt=tot_cnt+1\n",
    "  tot_freq=tot_freq+value\n",
    "  if(value<thresh):\n",
    "    cnt=cnt+1\n",
    "    freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Build a word-index pair dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign index, starting from 2\n",
    "source_word_index={}\n",
    "cnt=2\n",
    "for key,value in source_word_freq.items():\n",
    "  # add token if it is not rare  \n",
    "  if(value>=thresh):\n",
    "    source_word_index[key]=cnt  \n",
    "    cnt=cnt+1\n",
    "\n",
    "# assign index to \"padding\" and \"unknown\" tokens\n",
    "source_word_index['<pad>']=0\n",
    "source_word_index['<unk>']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Create integer-sequences from the spanish sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab=[key for key,value in source_word_index.items()]  #spanish vocabulary\n",
    "\n",
    "# sentences to integer sequences (Spanish sentences - training data)\n",
    "source_seq_tr=[]\n",
    "for i in x_tr:\n",
    "  seq=[]\n",
    "  for j in i.split():\n",
    "    if(j not in source_vocab):\n",
    "      seq.append(source_word_index['<unk>'])\n",
    "    elif(source_word_freq[j]<thresh):\n",
    "      seq.append(source_word_index['<unk>'])\n",
    "    else:\n",
    "      seq.append(source_word_index[j])\n",
    "  source_seq_tr.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 5, 6, 7],\n",
       " [8, 9, 10, 11, 12, 13],\n",
       " [13, 14, 15, 13, 16, 17, 18],\n",
       " [9, 19, 20, 13, 21],\n",
       " [22, 1, 23, 24, 25, 26, 27, 4, 28, 4, 29, 30],\n",
       " [31, 26, 1, 32, 33, 34],\n",
       " [35, 36, 37, 38, 39],\n",
       " [4, 40, 41, 42, 20, 43, 38, 44],\n",
       " [45, 46, 47],\n",
       " [9, 48, 49, 50]]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_seq_tr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences to integer sequences (Spanish sentences - validation data)\n",
    "source_seq_val=[]\n",
    "for i in x_val:\n",
    "  seq=[]\n",
    "  for j in i.split():\n",
    "    if(j not in source_vocab):\n",
    "      seq.append(source_word_index['<unk>'])\n",
    "    elif(source_word_freq[j]<thresh):\n",
    "      seq.append(source_word_index['<unk>'])\n",
    "    else:\n",
    "      seq.append(source_word_index[j])\n",
    "  source_seq_val.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english word-frequency dictionary\n",
    "target_word_freq = build_vocab(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of rare words: 33.86594559160931\n",
      "Total Coverage of rare words: 0.6956612484872355\n"
     ]
    }
   ],
   "source": [
    "thresh=2 # set threshold count \n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in target_word_freq.items():\n",
    "  tot_cnt=tot_cnt+1\n",
    "  tot_freq=tot_freq+value\n",
    "  if(value<thresh):\n",
    "    cnt=cnt+1\n",
    "    freq=freq+value\n",
    "    \n",
    "print(\"Vocabulary of rare words:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Build a dictionary that assigns index to every word in the vocabulary by removing the rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_index={}\n",
    "\n",
    "cnt=4 # start assigning index from 4 \n",
    "for key,value in target_word_freq.items():\n",
    "  if(value>=thresh):\n",
    "    target_word_index[key]=cnt  \n",
    "    cnt=cnt+1\n",
    "\n",
    "# Assign index to \"padding\" and \"unknown\" token\n",
    "target_word_index['<pad>']=0\n",
    "target_word_index['<unk>']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Create integer-sequences from the English sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab=[key for key,value in target_word_index.items()]  #English vocabulary\n",
    "\n",
    "# sentences to integer sequences (Engish sentences - training data)\n",
    "target_seq_tr=[]\n",
    "for i in y_tr:\n",
    "  seq=[]\n",
    "  for j in i.split():\n",
    "    if(j not in target_vocab):\n",
    "      seq.append(target_word_index['<unk>'])\n",
    "    elif(target_word_freq[j]<thresh):\n",
    "      seq.append(target_word_index['<unk>'])\n",
    "    else:\n",
    "      seq.append(target_word_index[j])\n",
    "  target_seq_tr.append(seq)\n",
    "\n",
    "# sentences to integer sequences (Engish sentences - validation data)\n",
    "target_seq_val=[]\n",
    "for i in y_val:\n",
    "  seq=[]\n",
    "  for j in i.split():\n",
    "    if(j not in target_vocab):\n",
    "      seq.append(target_word_index['<unk>'])\n",
    "    elif(target_word_freq[j]<thresh):\n",
    "      seq.append(target_word_index['<unk>'])\n",
    "    else:\n",
    "      seq.append(target_word_index[j])\n",
    "  target_seq_val.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Pad the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check sentence length\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eng_word_count = []\n",
    "spa_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['eng']:\n",
    "      eng_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['spa']:\n",
    "      spa_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_word_count, 'spa':spa_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set maximum length for English and Spanish sentences\n",
    "max_eng_len=15\n",
    "max_spa_len=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad Spanish sequences\n",
    "x_tr = pad_sequences(source_seq_tr,  maxlen=max_spa_len, padding='post', truncating='post')\n",
    "x_val = pad_sequences(source_seq_val, maxlen=max_spa_len, padding='post', truncating='post')\n",
    "x_voc = len(source_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad English sequences\n",
    "y_tr_pad    =   pad_sequences(target_seq_tr, maxlen=max_eng_len, padding='post', truncating=\"post\")\n",
    "y_val_pad   =   pad_sequences(target_seq_val, maxlen=max_eng_len, padding='post', truncating=\"post\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special tokens for the training data\n",
    "target_word_index['<start>']=2\n",
    "target_word_index['<end>']=3\n",
    "\n",
    "# Add start token to target sequences\n",
    "y_tr_start=[]\n",
    "for i in y_tr_pad:\n",
    "  temp=np.insert(i,0,target_word_index['<start>'])\n",
    "  y_tr_start.append(temp)\n",
    "\n",
    "#Add end token to target sequences \n",
    "y_tr=[]\n",
    "for i in y_tr_start:\n",
    "  if(0 in list(i)):\n",
    "    temp=np.insert(i,list(i).index(0),target_word_index['<end>'])\n",
    "  else:\n",
    "    temp=np.insert(i,len(i),target_word_index['<end>'])\n",
    "  y_tr.append(temp)\n",
    "  \n",
    "y_tr=np.array(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_voc = len(target_word_index)   #size of english vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special tokens for the validation data\n",
    "\n",
    "# Add start token to target sequences\n",
    "y_val_start=[]\n",
    "for i in y_val_pad:\n",
    "  temp=np.insert(i,0,target_word_index['<start>'])\n",
    "  y_val_start.append(temp)\n",
    "\n",
    "# Add end token to target sequences \n",
    "y_val=[]\n",
    "for i in y_val_start:\n",
    "  if(0 in list(i)):\n",
    "    temp=np.insert(i,list(i).index(0),target_word_index['<end>'])\n",
    "  else:\n",
    "    temp=np.insert(i,len(i),target_word_index['<end>'])\n",
    "  y_val.append(temp)\n",
    "  \n",
    "y_val=np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update maximum length\n",
    "max_eng_len=max_eng_len+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hidden units\n",
    "latent_dim = 150 \n",
    "\n",
    "# specify length of word embeddings \n",
    "embedding_dim=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(max_spa_len,))\n",
    "enc_emb =  Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(__encoder_outputs__: all the hidden states, __state_h__: final hidden state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Architecture, using \"encoder_states\" as initial state.\n",
    "decoder_inputs = Input(shape=(max_eng_len-1,))\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_output) # probability distribution of vocab words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 15, 200)      2636800     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 16, 200)      1615000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 15, 150), (N 210600      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 16, 150), (N 210600      embedding_4[0][0]                \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 16, 8075)     1219325     lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,892,325\n",
      "Trainable params: 5,892,325\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, min_delta=0.0001)\n",
    "mc = ModelCheckpoint('best_model_v4.h5',monitor='val_loss',mode='min', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:],\n",
    "                  epochs=100,callbacks=[es,mc], batch_size=512, \n",
    "                  validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model and save its weights\n",
    "model = load_model('best_model_v4.h5')\n",
    "model.save_weights('best_model_weights_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('best_model_weights_v4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap dictionary pairs\n",
    "reverse_target_word_index=dict((v, k) for k, v in target_word_index.items())\n",
    "reverse_source_word_index=dict((v, k) for k, v in source_word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the context vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "## decoder_hidden_state_input = Input(shape=(max_spa_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "decoder_inputs_2 = Input(shape=(None,))\n",
    "dec_emb2= dec_emb_layer(decoder_inputs_2) \n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_2] + [decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['<start>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) \n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='<end>'):\n",
    "            decoded_sentence= decoded_sentence+sampled_token+' '\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == '<end>'  or len(decoded_sentence.split()) >= (max_eng_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate a few sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample from the validation data\n",
    "target = y_val_original[15000:15050].tolist()\n",
    "source = x_val_original[15000:15050].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=[]\n",
    "for i in x_val[15000:15050]:\n",
    "    predicted.append(decode_sequence(i.reshape(1,max_spa_len)))\n",
    "\n",
    "# add the actual and the predicted sentences to a dataframe\n",
    "df=pd.DataFrame({\"Source\":source,\"Target\":target,\"predicted\":predicted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ahora es imposible salir</td>\n",
       "      <td>its impossible to go out now</td>\n",
       "      <td>it is impossible now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tienen dos hijos y una hija</td>\n",
       "      <td>they have two sons and one daughter</td>\n",
       "      <td>they have two sons and only a daughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hablo frances</td>\n",
       "      <td>i speak french</td>\n",
       "      <td>i speak french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tenemos frio</td>\n",
       "      <td>were cold</td>\n",
       "      <td>we need cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tom es un antiguo paracaidista</td>\n",
       "      <td>tom is a former paratrooper</td>\n",
       "      <td>tom is a &lt;unk&gt; old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oi que podria nevar</td>\n",
       "      <td>i heard it might snow</td>\n",
       "      <td>i heard that might rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tom todavia no sabe la verdad</td>\n",
       "      <td>tom doesnt know the truth yet</td>\n",
       "      <td>tom doesnt know yet he is true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>el avion se aproximaba a londres</td>\n",
       "      <td>the plane was approaching london</td>\n",
       "      <td>the plane will be flying to the club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>su pelo era castano</td>\n",
       "      <td>his hair was brown</td>\n",
       "      <td>his hair was brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>me alegra que estemos juntos ahora</td>\n",
       "      <td>im glad were together now</td>\n",
       "      <td>were glad youre out of that things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>puedo olerlo desde aqui</td>\n",
       "      <td>i can smell it from here</td>\n",
       "      <td>i can get here from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ambos tom y mary observaron a john</td>\n",
       "      <td>tom and mary both stared at john</td>\n",
       "      <td>tom and mary both john were &lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tengo algunos asuntos inconclusos de los que ocuparme</td>\n",
       "      <td>i have some unfinished business to take care of</td>\n",
       "      <td>i have some &lt;unk&gt; to carry business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>un problema tal es dificil de tratar</td>\n",
       "      <td>such a problem is hard to deal with</td>\n",
       "      <td>a problem is hard to be sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>es seguro nadar en este rio</td>\n",
       "      <td>is it safe to swim in this river</td>\n",
       "      <td>is it sure to swim in this river</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>el le pidio a ella su consejo acerca del problema</td>\n",
       "      <td>he asked her advice about the problem</td>\n",
       "      <td>she asked her for her advice about the problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>esta es la razon por la que lo hizo</td>\n",
       "      <td>this is the reason why he did it</td>\n",
       "      <td>is it the reason why he is not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tengo muchas fotos</td>\n",
       "      <td>i have a lot of photos</td>\n",
       "      <td>i have a lot of stamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>maria usa demasiado maquillaje</td>\n",
       "      <td>mary wears too much makeup</td>\n",
       "      <td>mary always wears expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>te vas a correr todos los dias</td>\n",
       "      <td>do you go running every day</td>\n",
       "      <td>are you going to run by day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>desafortunadamente me perdi toda la diversion</td>\n",
       "      <td>unfortunately i missed all the fun</td>\n",
       "      <td>i all was the lucky that we lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a medida que pasaba el tiempo la gente se iba preocupando cada vez mas por la cuestion</td>\n",
       "      <td>as time went on people grew more and more concerned about the matter</td>\n",
       "      <td>in case it rains &lt;unk&gt; on the heavy weather &lt;unk&gt; the crops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>alguien sabe que hora es</td>\n",
       "      <td>does anyone know what time it is</td>\n",
       "      <td>does anyone know what time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>no me gaste ni un centimo</td>\n",
       "      <td>i didnt spend a penny</td>\n",
       "      <td>i didnt have any time i looked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yo creo que ellas te conocen</td>\n",
       "      <td>i think they know you</td>\n",
       "      <td>i think they know you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nosotros vendremos a visitarte</td>\n",
       "      <td>well come and visit you</td>\n",
       "      <td>we will visit you in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>contra viento y marea consiguio lo que queria</td>\n",
       "      <td>he got what he wanted against all odds</td>\n",
       "      <td>it is as strong as we thought it over the police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>es un error comun</td>\n",
       "      <td>its a common mistake</td>\n",
       "      <td>it is a common mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>estoy rezando</td>\n",
       "      <td>i am praying</td>\n",
       "      <td>im &lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pase las vacaciones decorando la casa</td>\n",
       "      <td>i spent the holidays decorating the house</td>\n",
       "      <td>i spent the &lt;unk&gt; vacation yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>el perro cruzo la calle</td>\n",
       "      <td>the dog walked across the street</td>\n",
       "      <td>the dog ran down the street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hoy no ando de humor para bromas</td>\n",
       "      <td>i am in no mood for joking</td>\n",
       "      <td>i dont have in a whole mood in this &lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sabes por que vine aqui</td>\n",
       "      <td>do you know the reason i came here</td>\n",
       "      <td>do you know why you came here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>a tom no le gusta este diseno</td>\n",
       "      <td>tom doesnt like this design</td>\n",
       "      <td>tom doesnt like this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>vamos al zoo</td>\n",
       "      <td>lets go to the zoo</td>\n",
       "      <td>lets go to the zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>necesito reemplazar mi piano por uno nuevo</td>\n",
       "      <td>i need to replace my keyboard with a new one</td>\n",
       "      <td>i need a piano or my sister will be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lamento no poder ayudaros</td>\n",
       "      <td>i regret that i cant help you</td>\n",
       "      <td>im sorry i cant help you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ya estaba oscuro cuando tom llego a casa</td>\n",
       "      <td>it was already dark when tom got home</td>\n",
       "      <td>it was just when the meeting was over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>me alegro de estar aqui</td>\n",
       "      <td>im happy to be here</td>\n",
       "      <td>im glad to be here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>te echare muchisimo de menos si te vas de japon</td>\n",
       "      <td>i will badly miss you if you leave japan</td>\n",
       "      <td>you will miss you very much but you want to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>con que frecuencia hablas frances</td>\n",
       "      <td>how often do you speak french</td>\n",
       "      <td>how often do you speak french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>por que no funciona esto</td>\n",
       "      <td>why isnt this working</td>\n",
       "      <td>why does this be working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>las cosas solo se pondran peor</td>\n",
       "      <td>things will only get worse</td>\n",
       "      <td>things &lt;unk&gt; said to happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>kenia consiguio la independencia en</td>\n",
       "      <td>kenya became independent in</td>\n",
       "      <td>he &lt;unk&gt; the &lt;unk&gt; up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>quiero saber donde estoy parado</td>\n",
       "      <td>i want to know where i stand</td>\n",
       "      <td>i want to know where im going to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>me gusta mucho cuidar de los animales</td>\n",
       "      <td>i like taking care of animals very much</td>\n",
       "      <td>i like to learn &lt;unk&gt; in &lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tom tiene un piano</td>\n",
       "      <td>tom has a piano</td>\n",
       "      <td>tom has a piano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>es mas barato ir en autobus</td>\n",
       "      <td>it is cheaper to go by bus</td>\n",
       "      <td>its cheaper to go on the bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tom perdio la voz</td>\n",
       "      <td>tom lost his voice</td>\n",
       "      <td>tom lost his voice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>el tiene que ser tonto para hacer eso</td>\n",
       "      <td>he must be a fool to do so</td>\n",
       "      <td>he has to be a word to say</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    Source  \\\n",
       "0                                                                 ahora es imposible salir   \n",
       "1                                                              tienen dos hijos y una hija   \n",
       "2                                                                            hablo frances   \n",
       "3                                                                             tenemos frio   \n",
       "4                                                           tom es un antiguo paracaidista   \n",
       "5                                                                      oi que podria nevar   \n",
       "6                                                            tom todavia no sabe la verdad   \n",
       "7                                                         el avion se aproximaba a londres   \n",
       "8                                                                      su pelo era castano   \n",
       "9                                                       me alegra que estemos juntos ahora   \n",
       "10                                                                 puedo olerlo desde aqui   \n",
       "11                                                      ambos tom y mary observaron a john   \n",
       "12                                   tengo algunos asuntos inconclusos de los que ocuparme   \n",
       "13                                                    un problema tal es dificil de tratar   \n",
       "14                                                             es seguro nadar en este rio   \n",
       "15                                       el le pidio a ella su consejo acerca del problema   \n",
       "16                                                     esta es la razon por la que lo hizo   \n",
       "17                                                                      tengo muchas fotos   \n",
       "18                                                          maria usa demasiado maquillaje   \n",
       "19                                                          te vas a correr todos los dias   \n",
       "20                                           desafortunadamente me perdi toda la diversion   \n",
       "21  a medida que pasaba el tiempo la gente se iba preocupando cada vez mas por la cuestion   \n",
       "22                                                                alguien sabe que hora es   \n",
       "23                                                               no me gaste ni un centimo   \n",
       "24                                                            yo creo que ellas te conocen   \n",
       "25                                                          nosotros vendremos a visitarte   \n",
       "26                                           contra viento y marea consiguio lo que queria   \n",
       "27                                                                       es un error comun   \n",
       "28                                                                           estoy rezando   \n",
       "29                                                   pase las vacaciones decorando la casa   \n",
       "30                                                                 el perro cruzo la calle   \n",
       "31                                                        hoy no ando de humor para bromas   \n",
       "32                                                                 sabes por que vine aqui   \n",
       "33                                                           a tom no le gusta este diseno   \n",
       "34                                                                            vamos al zoo   \n",
       "35                                              necesito reemplazar mi piano por uno nuevo   \n",
       "36                                                               lamento no poder ayudaros   \n",
       "37                                                ya estaba oscuro cuando tom llego a casa   \n",
       "38                                                                 me alegro de estar aqui   \n",
       "39                                         te echare muchisimo de menos si te vas de japon   \n",
       "40                                                       con que frecuencia hablas frances   \n",
       "41                                                                por que no funciona esto   \n",
       "42                                                          las cosas solo se pondran peor   \n",
       "43                                                     kenia consiguio la independencia en   \n",
       "44                                                         quiero saber donde estoy parado   \n",
       "45                                                   me gusta mucho cuidar de los animales   \n",
       "46                                                                      tom tiene un piano   \n",
       "47                                                             es mas barato ir en autobus   \n",
       "48                                                                       tom perdio la voz   \n",
       "49                                                   el tiene que ser tonto para hacer eso   \n",
       "\n",
       "                                                                  Target  \\\n",
       "0                                           its impossible to go out now   \n",
       "1                                    they have two sons and one daughter   \n",
       "2                                                         i speak french   \n",
       "3                                                              were cold   \n",
       "4                                            tom is a former paratrooper   \n",
       "5                                                  i heard it might snow   \n",
       "6                                          tom doesnt know the truth yet   \n",
       "7                                       the plane was approaching london   \n",
       "8                                                     his hair was brown   \n",
       "9                                              im glad were together now   \n",
       "10                                              i can smell it from here   \n",
       "11                                      tom and mary both stared at john   \n",
       "12                       i have some unfinished business to take care of   \n",
       "13                                   such a problem is hard to deal with   \n",
       "14                                      is it safe to swim in this river   \n",
       "15                                 he asked her advice about the problem   \n",
       "16                                      this is the reason why he did it   \n",
       "17                                                i have a lot of photos   \n",
       "18                                            mary wears too much makeup   \n",
       "19                                           do you go running every day   \n",
       "20                                    unfortunately i missed all the fun   \n",
       "21  as time went on people grew more and more concerned about the matter   \n",
       "22                                      does anyone know what time it is   \n",
       "23                                                 i didnt spend a penny   \n",
       "24                                                 i think they know you   \n",
       "25                                               well come and visit you   \n",
       "26                                he got what he wanted against all odds   \n",
       "27                                                  its a common mistake   \n",
       "28                                                          i am praying   \n",
       "29                             i spent the holidays decorating the house   \n",
       "30                                      the dog walked across the street   \n",
       "31                                            i am in no mood for joking   \n",
       "32                                    do you know the reason i came here   \n",
       "33                                           tom doesnt like this design   \n",
       "34                                                    lets go to the zoo   \n",
       "35                          i need to replace my keyboard with a new one   \n",
       "36                                         i regret that i cant help you   \n",
       "37                                 it was already dark when tom got home   \n",
       "38                                                   im happy to be here   \n",
       "39                              i will badly miss you if you leave japan   \n",
       "40                                         how often do you speak french   \n",
       "41                                                 why isnt this working   \n",
       "42                                            things will only get worse   \n",
       "43                                           kenya became independent in   \n",
       "44                                          i want to know where i stand   \n",
       "45                               i like taking care of animals very much   \n",
       "46                                                       tom has a piano   \n",
       "47                                            it is cheaper to go by bus   \n",
       "48                                                    tom lost his voice   \n",
       "49                                            he must be a fool to do so   \n",
       "\n",
       "                                                      predicted  \n",
       "0                                          it is impossible now  \n",
       "1                        they have two sons and only a daughter  \n",
       "2                                                i speak french  \n",
       "3                                                  we need cold  \n",
       "4                                            tom is a <unk> old  \n",
       "5                                       i heard that might rain  \n",
       "6                                tom doesnt know yet he is true  \n",
       "7                          the plane will be flying to the club  \n",
       "8                                            his hair was brown  \n",
       "9                            were glad youre out of that things  \n",
       "10                                          i can get here from  \n",
       "11                            tom and mary both john were <unk>  \n",
       "12                          i have some <unk> to carry business  \n",
       "13                                 a problem is hard to be sure  \n",
       "14                             is it sure to swim in this river  \n",
       "15               she asked her for her advice about the problem  \n",
       "16                               is it the reason why he is not  \n",
       "17                                       i have a lot of stamps  \n",
       "18                                  mary always wears expensive  \n",
       "19                                  are you going to run by day  \n",
       "20                             i all was the lucky that we lost  \n",
       "21  in case it rains <unk> on the heavy weather <unk> the crops  \n",
       "22                                   does anyone know what time  \n",
       "23                               i didnt have any time i looked  \n",
       "24                                        i think they know you  \n",
       "25                                         we will visit you in  \n",
       "26             it is as strong as we thought it over the police  \n",
       "27                                       it is a common mistake  \n",
       "28                                                     im <unk>  \n",
       "29                         i spent the <unk> vacation yesterday  \n",
       "30                                  the dog ran down the street  \n",
       "31                    i dont have in a whole mood in this <unk>  \n",
       "32                                do you know why you came here  \n",
       "33                                         tom doesnt like this  \n",
       "34                                           lets go to the zoo  \n",
       "35                          i need a piano or my sister will be  \n",
       "36                                     im sorry i cant help you  \n",
       "37                        it was just when the meeting was over  \n",
       "38                                           im glad to be here  \n",
       "39                  you will miss you very much but you want to  \n",
       "40                                how often do you speak french  \n",
       "41                                     why does this be working  \n",
       "42                                  things <unk> said to happen  \n",
       "43                                        he <unk> the <unk> up  \n",
       "44                             i want to know where im going to  \n",
       "45                               i like to learn <unk> in <unk>  \n",
       "46                                              tom has a piano  \n",
       "47                                 its cheaper to go on the bus  \n",
       "48                                           tom lost his voice  \n",
       "49                                   he has to be a word to say  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
